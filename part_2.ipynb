{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "032c550f-fdd6-4aa0-bcbd-6ac4ff88471c",
      "metadata": {
        "id": "032c550f-fdd6-4aa0-bcbd-6ac4ff88471c",
        "outputId": "5218e22a-6fc2-48a0-c9d0-0272af09e8bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Rose\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Set device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03633e3c-85cf-4b36-bada-43a0559742d9",
      "metadata": {
        "id": "03633e3c-85cf-4b36-bada-43a0559742d9",
        "outputId": "c027a2bb-0c78-4edb-ebc8-315c69771636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  English      French\n",
            "0     Go.        Va !\n",
            "1    Run!     Cours !\n",
            "2    Run!    Courez !\n",
            "3    Wow!  Ça alors !\n",
            "4   Fire!    Au feu !\n"
          ]
        }
      ],
      "source": [
        "file_path = r\"C:\\Users\\Rose\\Documents\\mcmaster\\semester 2\\NLP\\assignments\\dataset french\\eng-fra.txt\"\n",
        "\n",
        "data = []\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(\"\\t\")  # Split by tab\n",
        "        if len(parts) == 2:  # Ensure it has both English and French parts\n",
        "            data.append(parts)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"English\", \"French\"])\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f42b97-9cad-45df-95b7-9949c9b64a5e",
      "metadata": {
        "id": "83f42b97-9cad-45df-95b7-9949c9b64a5e",
        "outputId": "1047f81e-0424-4ea8-d912-95d6218a5cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     English          French\n",
            "0    [go, .]         [va, !]\n",
            "1   [run, !]      [cours, !]\n",
            "2   [run, !]     [courez, !]\n",
            "3   [wow, !]  [ça, alors, !]\n",
            "4  [fire, !]    [au, feu, !]\n"
          ]
        }
      ],
      "source": [
        "# Tokenization function using NLTK\n",
        "def tokenize(sentence):\n",
        "    return word_tokenize(sentence.lower())  # Convert to lowercase for consistency\n",
        "\n",
        "# Apply tokenization to both columns\n",
        "df['English'] = df['English'].apply(tokenize)\n",
        "df['French'] = df['French'].apply(tokenize)\n",
        "\n",
        "# show tokenized data\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd34e8bc-a7ea-439b-ae0f-8971297655d5",
      "metadata": {
        "id": "cd34e8bc-a7ea-439b-ae0f-8971297655d5"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.word2idx = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}  # Special tokens\n",
        "        self.idx2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.word_count = {}\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence:\n",
        "            if word not in self.word2idx:\n",
        "                idx = len(self.word2idx)\n",
        "                self.word2idx[word] = idx\n",
        "                self.idx2word[idx] = word\n",
        "            self.word_count[word] = self.word_count.get(word, 0) + 1\n",
        "\n",
        "    def numericalize(self, sentence):\n",
        "        return [self.word2idx.get(word, self.word2idx[\"<UNK>\"]) for word in sentence]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7836e078-065b-4ebc-a665-2f4a0b9b5581",
      "metadata": {
        "id": "7836e078-065b-4ebc-a665-2f4a0b9b5581",
        "outputId": "9b4bb879-148c-4527-c47d-8745589d0d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 7004\n",
            "French Vocabulary Size: 10848\n"
          ]
        }
      ],
      "source": [
        "# Initialize vocabularies\n",
        "eng_vocab = Vocabulary()\n",
        "fr_vocab = Vocabulary()\n",
        "\n",
        "# Populate vocabularies\n",
        "for _, row in df.iterrows():\n",
        "    eng_vocab.add_sentence(row['English'])\n",
        "    fr_vocab.add_sentence(row['French'])\n",
        "\n",
        "# Print vocabulary size\n",
        "print(f\"English Vocabulary Size: {len(eng_vocab.word2idx)}\")\n",
        "print(f\"French Vocabulary Size: {len(fr_vocab.word2idx)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2d008ce-8877-4866-8a97-71a681851f2c",
      "metadata": {
        "id": "d2d008ce-8877-4866-8a97-71a681851f2c",
        "outputId": "fcfe5ed0-c556-485f-8e6b-6d1ec3d52430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  English             French\n",
            "0  [4, 5]       [1, 4, 5, 2]\n",
            "1  [6, 7]       [1, 6, 5, 2]\n",
            "2  [6, 7]       [1, 7, 5, 2]\n",
            "3  [8, 7]    [1, 8, 9, 5, 2]\n",
            "4  [9, 7]  [1, 10, 11, 5, 2]\n"
          ]
        }
      ],
      "source": [
        "# Convert tokenized sentences into numerical sequences\n",
        "df['English'] = df['English'].apply(eng_vocab.numericalize)\n",
        "df['French'] = df['French'].apply(lambda x: [fr_vocab.word2idx['<SOS>']] + fr_vocab.numericalize(x) + [fr_vocab.word2idx['<EOS>']])\n",
        "\n",
        "# Display converted sequences\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df44fadc-a686-412c-a494-4840cf18bbe2",
      "metadata": {
        "id": "df44fadc-a686-412c-a494-4840cf18bbe2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, df, eng_vocab, fr_vocab, max_len=10):\n",
        "        self.data = df\n",
        "        self.eng_vocab = eng_vocab\n",
        "        self.fr_vocab = fr_vocab\n",
        "        self.max_len = max_len  # Max sequence length for padding\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def pad_sequence(self, seq, pad_idx):\n",
        "        \"\"\"Pad sequences to max_len with <PAD> tokens.\"\"\"\n",
        "        return seq + [pad_idx] * (self.max_len - len(seq)) if len(seq) < self.max_len else seq[:self.max_len]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        eng_seq = self.pad_sequence(self.data.iloc[index]['English'], self.eng_vocab.word2idx['<PAD>'])\n",
        "        fr_seq = self.pad_sequence(self.data.iloc[index]['French'], self.fr_vocab.word2idx['<PAD>'])\n",
        "        return torch.tensor(eng_seq, dtype=torch.long), torch.tensor(fr_seq, dtype=torch.long)\n",
        "\n",
        "# Create dataset instance\n",
        "dataset = TranslationDataset(df, eng_vocab, fr_vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6967e8e-0371-46c8-ac7e-0b6f96d8e5c2",
      "metadata": {
        "id": "b6967e8e-0371-46c8-ac7e-0b6f96d8e5c2",
        "outputId": "7e85f183-ccb6-4ebf-a622-a24a7db20487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English batch shape: torch.Size([64, 10])\n",
            "French batch shape: torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "# Create DataLoader for batching\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Fetch one batch to check\n",
        "for eng_batch, fr_batch in dataloader:\n",
        "    print(\"English batch shape:\", eng_batch.shape)\n",
        "    print(\"French batch shape:\", fr_batch.shape)\n",
        "    break  # Print only the first batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7724f43e-02f3-4875-aaec-60ec601e9a08",
      "metadata": {
        "id": "7724f43e-02f3-4875-aaec-60ec601e9a08"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)  # Convert word indices to embeddings\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)  # LSTM processing\n",
        "        return outputs, hidden, cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a354a9a4-5b58-45f6-9d62-fd10211685b9",
      "metadata": {
        "id": "a354a9a4-5b58-45f6-9d62-fd10211685b9"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)  # Combine encoder & decoder hidden states\n",
        "        self.v = nn.Linear(hidden_dim, 1, bias=False)  # Compute attention scores\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        seq_len = encoder_outputs.shape[1]  # Get sequence length\n",
        "        hidden = hidden[-1].unsqueeze(1).repeat(1, seq_len, 1)  # Repeat hidden state across sequence\n",
        "\n",
        "        # Compute energy scores\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)  # Compute final attention scores\n",
        "\n",
        "        return torch.softmax(attention, dim=1)  # Normalize scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f71894-0bad-4d14-95cb-5b1955180317",
      "metadata": {
        "id": "81f71894-0bad-4d14-95cb-5b1955180317"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, attention):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim + hidden_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)  # Use both LSTM output + Attention\n",
        "        self.attention = attention\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(1)  # Add sequence dimension\n",
        "        embedded = self.embedding(input)\n",
        "\n",
        "        # Apply attention\n",
        "        attn_weights = self.attention(hidden, encoder_outputs)  # Compute attention weights\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)  # Weighted sum of encoder outputs\n",
        "\n",
        "        lstm_input = torch.cat((embedded, attn_applied), dim=2)  # Combine embedding with attention\n",
        "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))  # Pass through LSTM\n",
        "\n",
        "        prediction = self.fc_out(torch.cat((output.squeeze(1), attn_applied.squeeze(1)), dim=1))  # Combine features\n",
        "\n",
        "        return prediction, hidden, cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aab45c3e-714a-4fc7-8ee9-7ae28f31854c",
      "metadata": {
        "id": "aab45c3e-714a-4fc7-8ee9-7ae28f31854c"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)  # Encode input\n",
        "        outputs = torch.zeros(trg.shape[1], trg.shape[0], self.decoder.fc_out.out_features).to(DEVICE)\n",
        "        input = trg[:, 0]  # Start decoding with <SOS>\n",
        "\n",
        "        for t in range(1, trg.shape[1]):  # Decode each timestep\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            input = output.argmax(1)  # Get predicted word\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d170932-43de-425d-9925-499194f3a15b",
      "metadata": {
        "id": "6d170932-43de-425d-9925-499194f3a15b",
        "outputId": "568bc2b9-367a-43d6-a569-37cd3785d4e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "# Define model parameters\n",
        "INPUT_DIM = len(eng_vocab.word2idx)\n",
        "OUTPUT_DIM = len(fr_vocab.word2idx)\n",
        "EMB_DIM = 256\n",
        "HIDDEN_DIM = 512\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "\n",
        "\n",
        "encoder = Encoder(INPUT_DIM, EMB_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT).to(DEVICE)\n",
        "attention = Attention(HIDDEN_DIM).to(DEVICE)\n",
        "decoder = Decoder(OUTPUT_DIM, EMB_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT, attention).to(DEVICE)\n",
        "model = Seq2Seq(encoder, decoder).to(DEVICE)\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"weight\" in name:\n",
        "                nn.init.orthogonal_(param)\n",
        "\n",
        "print(\"Model initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9817c891-fb72-42fd-b84a-8c8ab010a667",
      "metadata": {
        "id": "9817c891-fb72-42fd-b84a-8c8ab010a667",
        "outputId": "7c4158a7-deb5-4b87-aa10-7419ee4d5976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder Outputs Shape: torch.Size([5, 10, 512])\n",
            "Encoder Hidden Shape: torch.Size([2, 5, 512])\n",
            "Encoder Cell Shape: torch.Size([2, 5, 512])\n"
          ]
        }
      ],
      "source": [
        "# Dummy input batch (batch_size=5, seq_len=10)\n",
        "dummy_src = torch.randint(0, INPUT_DIM, (5, 10)).to(DEVICE)\n",
        "\n",
        "# Forward pass through the encoder\n",
        "encoder_outputs, hidden, cell = encoder(dummy_src)\n",
        "\n",
        "# Print shapes\n",
        "print(\"Encoder Outputs Shape:\", encoder_outputs.shape)\n",
        "print(\"Encoder Hidden Shape:\", hidden.shape)\n",
        "print(\"Encoder Cell Shape:\", cell.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56897c53-7385-4f0b-b34f-8cb48c470384",
      "metadata": {
        "id": "56897c53-7385-4f0b-b34f-8cb48c470384",
        "outputId": "c1847dae-96ed-4628-ccf8-0b83269cec89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attention Weights Shape: torch.Size([5, 10])\n"
          ]
        }
      ],
      "source": [
        "# Forward pass through the attention layer\n",
        "attn_weights = attention(hidden, encoder_outputs)\n",
        "\n",
        "# Print shapes\n",
        "print(\"Attention Weights Shape:\", attn_weights.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b272577-e2f7-4b7e-92df-cc77570e3151",
      "metadata": {
        "id": "4b272577-e2f7-4b7e-92df-cc77570e3151",
        "outputId": "dae9b509-7625-4947-9a47-e210f2f353e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoder Output Shape: torch.Size([5, 10848])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 512])\n",
            "Decoder Cell Shape: torch.Size([2, 5, 512])\n"
          ]
        }
      ],
      "source": [
        "# Dummy target input (batch_size=5)\n",
        "dummy_trg = torch.randint(0, OUTPUT_DIM, (5,)).to(DEVICE)\n",
        "\n",
        "# Forward pass through the decoder\n",
        "decoder_output, hidden, cell = decoder(dummy_trg, hidden, cell, encoder_outputs)\n",
        "\n",
        "# Print shapes\n",
        "print(\"Decoder Output Shape:\", decoder_output.shape)\n",
        "print(\"Decoder Hidden Shape:\", hidden.shape)\n",
        "print(\"Decoder Cell Shape:\", cell.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb9a65d4-d4aa-451a-a7a4-85b21aa2b114",
      "metadata": {
        "id": "fb9a65d4-d4aa-451a-a7a4-85b21aa2b114",
        "outputId": "92f0f440-62bb-42a7-9622-bb18955c7526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seq2Seq Output Shape: torch.Size([10, 5, 10848])\n"
          ]
        }
      ],
      "source": [
        "# Dummy target sequence (batch_size=5, seq_len=10)\n",
        "dummy_trg = torch.randint(0, OUTPUT_DIM, (5, 10)).to(DEVICE)\n",
        "\n",
        "# Forward pass through Seq2Seq model\n",
        "outputs = model(dummy_src, dummy_trg)\n",
        "\n",
        "# Print shape\n",
        "print(\"Seq2Seq Output Shape:\", outputs.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16373663-395a-45b0-a596-07e94db44fdb",
      "metadata": {
        "id": "16373663-395a-45b0-a596-07e94db44fdb",
        "outputId": "8219b113-9f5d-4d89-e4f5-50362eb43343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss function and optimizer initialized.\n"
          ]
        }
      ],
      "source": [
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=eng_vocab.word2idx[\"<PAD>\"])  # Ignore <PAD> tokens\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.009)\n",
        "\n",
        "print(\"Loss function and optimizer initialized.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b41298f-6a19-4923-9c05-cba02548261d",
      "metadata": {
        "id": "5b41298f-6a19-4923-9c05-cba02548261d",
        "outputId": "98a54985-2b45-46c1-a285-2c8f318035cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 6.9513 | Time: 5m 23s\n",
            "Epoch 2: Train Loss = 6.6708 | Time: 5m 46s\n",
            "Epoch 3: Train Loss = 6.6584 | Time: 6m 0s\n",
            "Epoch 4: Train Loss = 6.5926 | Time: 5m 26s\n",
            "Epoch 5: Train Loss = 6.5839 | Time: 5m 41s\n",
            "Epoch 6: Train Loss = 6.5787 | Time: 5m 38s\n",
            "Epoch 7: Train Loss = 6.5726 | Time: 5m 47s\n",
            "Epoch 8: Train Loss = 6.5719 | Time: 8m 45s\n",
            "Epoch 9: Train Loss = 6.5715 | Time: 9m 40s\n",
            "Epoch 10: Train Loss = 6.5720 | Time: 9m 22s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training function\n",
        "def train(model, dataloader, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for eng_batch, fr_batch in dataloader:\n",
        "        eng_batch, fr_batch = eng_batch.to(DEVICE), fr_batch.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        output = model(eng_batch, fr_batch)  # Forward pass\n",
        "\n",
        "        # Reshape output and target for loss calculation\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].reshape(-1, output_dim)\n",
        "        target = fr_batch[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, target)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  # Prevent exploding gradients\n",
        "        optimizer.step()  # Update model weights\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "# Training loop\n",
        "N_EPOCHS = 10 #since it takes a long time\n",
        "\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, dataloader, optimizer, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = divmod(int(end_time - start_time), 60)\n",
        "\n",
        "    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f} | Time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6fb028f-c761-43ce-8cc8-093e6c3946fd",
      "metadata": {
        "id": "e6fb028f-c761-43ce-8cc8-093e6c3946fd",
        "outputId": "26b3c3d3-5ed1-44d0-d30b-b22d8a74cbca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: hi how are you!\n",
            "French: de de de de de de de de de\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def translate_sentence(model, sentence, eng_vocab, fr_vocab, max_len=10):\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    tokens = word_tokenize(sentence.lower())  # Tokenize input\n",
        "    numericalized = [eng_vocab.word2idx.get(token, eng_vocab.word2idx[\"<UNK>\"]) for token in tokens]\n",
        "\n",
        "    input_tensor = torch.tensor(numericalized, dtype=torch.long).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
        "    encoder_outputs, hidden, cell = model.encoder(input_tensor)  # Get encoder outputs\n",
        "\n",
        "    trg_indexes = [fr_vocab.word2idx[\"<SOS>\"]]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.tensor([trg_indexes[-1]], dtype=torch.long).to(DEVICE)\n",
        "        output, hidden, cell = model.decoder(trg_tensor, hidden, cell, encoder_outputs)\n",
        "\n",
        "        predicted_token = output.argmax(1).item()  # Get best word\n",
        "        trg_indexes.append(predicted_token)\n",
        "\n",
        "        if predicted_token == fr_vocab.word2idx[\"<EOS>\"]:\n",
        "            break\n",
        "\n",
        "    translated_tokens = [fr_vocab.idx2word[i] for i in trg_indexes[1:-1]]  # Remove <SOS> & <EOS>\n",
        "    return \" \".join(translated_tokens)\n",
        "\n",
        "# Test translation\n",
        "test_sentence = \"hi how are you!\"\n",
        "translated_sentence = translate_sentence(model, test_sentence, eng_vocab, fr_vocab)\n",
        "print(f\"English: {test_sentence}\")\n",
        "print(f\"French: {translated_sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7829b9-e81a-4f27-8632-89a5fe702fa8",
      "metadata": {
        "scrolled": true,
        "id": "9a7829b9-e81a-4f27-8632-89a5fe702fa8",
        "outputId": "feb4fc41-4f70-42e1-a8f6-47cde2c94f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in d:\\new folder\\lib\\site-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in d:\\new folder\\lib\\site-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in d:\\new folder\\lib\\site-packages (from sacrebleu) (2023.10.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in d:\\new folder\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\new folder\\lib\\site-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in d:\\new folder\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in d:\\new folder\\lib\\site-packages (from sacrebleu) (5.2.1)\n",
            "Requirement already satisfied: pywin32>=226 in d:\\new folder\\lib\\site-packages (from portalocker->sacrebleu) (305.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "facd0d16-278e-4fdd-a12d-4b8e13f40c71",
      "metadata": {
        "id": "facd0d16-278e-4fdd-a12d-4b8e13f40c71",
        "outputId": "3e4422df-0788-420e-c352-89e759e7e08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU Score: 0.0848\n"
          ]
        }
      ],
      "source": [
        "import sacrebleu\n",
        "\n",
        "def evaluate_bleu(model, df_sample, eng_vocab, fr_vocab):\n",
        "    model.eval()\n",
        "    references = []\n",
        "    hypotheses = []\n",
        "\n",
        "    num_samples = min(100, len(df_sample))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Convert numericalized source sentence back to words\n",
        "        src_tokens = df_sample.iloc[i][\"English\"]\n",
        "        src_sentence = \" \".join([eng_vocab.idx2word[token] for token in src_tokens if token not in [0, 1, 2, 3]])\n",
        "\n",
        "        # Convert numericalized target sentence back to words\n",
        "        trg_tokens = df_sample.iloc[i][\"French\"][1:-1]  # Remove <SOS> and <EOS>\n",
        "        target_sentence = \" \".join([fr_vocab.idx2word[token] for token in trg_tokens if token not in [0, 1, 2, 3]])\n",
        "\n",
        "        # Get model translation\n",
        "        translated_sentence = translate_sentence(model, src_sentence, eng_vocab, fr_vocab)\n",
        "\n",
        "        references.append(target_sentence)  # List of reference sentences\n",
        "        hypotheses.append(translated_sentence)  # List of model translations\n",
        "\n",
        "    # Compute BLEU score using SacreBLEU\n",
        "    bleu_score = sacrebleu.corpus_bleu(hypotheses, [references]).score\n",
        "\n",
        "    return bleu_score\n",
        "\n",
        "# Evaluate BLEU score\n",
        "bleu_score = evaluate_bleu(model, df, eng_vocab, fr_vocab)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e234d9e4-5a07-4a6b-bed3-9ce78095a0ff",
      "metadata": {
        "id": "e234d9e4-5a07-4a6b-bed3-9ce78095a0ff",
        "outputId": "6817b4c3-d42f-4464-935d-0d62eeb79c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Save model state\n",
        "torch.save(model.state_dict(), \"seq2seq_model.pth\")\n",
        "print(\"Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5e2dd6f-6b0d-4486-8c0c-8fafa971b3a7",
      "metadata": {
        "id": "b5e2dd6f-6b0d-4486-8c0c-8fafa971b3a7",
        "outputId": "d9acc52c-07ab-4ca6-de24-efa8a924f624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"seq2seq_model.pth\", map_location=DEVICE))\n",
        "model.eval()  # Set to evaluation mode\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23b5c0d-9ced-4199-af0b-fc9078e50663",
      "metadata": {
        "id": "b23b5c0d-9ced-4199-af0b-fc9078e50663"
      },
      "outputs": [],
      "source": [
        "test_sentence = \"I love learning languages!\"\n",
        "translated_sentence = translate_sentence(model, test_sentence, eng_vocab, fr_vocab)\n",
        "print(f\"English: {test_sentence}\")\n",
        "print(f\"French: {translated_sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71f2d3ba-5a0e-4961-94f1-851903143a9b",
      "metadata": {
        "id": "71f2d3ba-5a0e-4961-94f1-851903143a9b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}